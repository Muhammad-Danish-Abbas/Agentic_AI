{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFVoViOJdd4LahxP8LMVdd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Muhammad-Danish-Abbas/Agentic_AI/blob/main/Project_3_Function_Tool_Calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Project 3: LangChain Function/Tool Calling Calculator"
      ],
      "metadata": {
        "id": "uM-hhixK4hTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain google-generativeai\n",
        "!pip install --upgrade google-generativeai\n",
        "!pip install python-dotenv # This line installs the missing package\n",
        "\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv # Now this import should work\n",
        "import google.generativeai as generativeai\n",
        "from langchain.tools import tool\n",
        "\n",
        "# ... (Rest of your code remains the same) ...\n",
        "\n",
        "# Load environment variables from the .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Fetch the Google Gemini API key from environment variable\n",
        "GOOGLE_GEMINI_API_KEY = os.getenv(\"GOOGLE_GEMINI_API_KEY\")\n",
        "\n",
        "# Step 1: Initialize Google Gemini Model using the correct method\n",
        "def gemini_model(query: str) -> str:\n",
        "    \"\"\"Use the Google Gemini API to generate text responses\"\"\"\n",
        "    try:\n",
        "        # Call the Google Gemini model with the chat method\n",
        "        generativeai.configure(api_key=GOOGLE_GEMINI_API_KEY)\n",
        "\n",
        "        # Use the `chat` method if it exists\n",
        "        response = generativeai.chat(\n",
        "            model=\"gemini-1\",  # Adjust the model name if needed\n",
        "            prompt=query\n",
        "        )\n",
        "\n",
        "        return response['text']\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "# Step 2: Define the Calculator Tool\n",
        "class Calculator:\n",
        "    def calculate(self, expression: str) -> str:\n",
        "        try:\n",
        "            result = eval(expression, {\"__builtins__\": None}, {})\n",
        "            return str(result)\n",
        "        except Exception as e:\n",
        "            return f\"Error: {e}\"\n",
        "\n",
        "# Step 3: Create the LangChain Tool Wrapper using the @tool decorator\n",
        "@tool\n",
        "def calculator_tool(expression: str) -> str:\n",
        "    \"\"\"\n",
        "    Perform basic arithmetic calculations.\n",
        "    Input: A mathematical expression as a string (e.g., \"2 + 2\").\n",
        "    Output: The result of the calculation as a string.\n",
        "    \"\"\"\n",
        "    calc = Calculator()\n",
        "    return calc.calculate(expression)\n",
        "\n",
        "# Step 4: Handle user input and interact with the calculator tool\n",
        "def handle_query(query: str):\n",
        "    # Call the Gemini model for generating a response\n",
        "    gemini_response = gemini_model(query)\n",
        "\n",
        "    # Check if the query is related to a calculation\n",
        "    if 'calculate' in query.lower():\n",
        "        # Example of passing calculation queries to the calculator\n",
        "        result = calculator_tool(query)\n",
        "        return f\"Gemini says: {gemini_response}\\nCalculator says: {result}\"\n",
        "\n",
        "    return gemini_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIs07BXO4k-c",
        "outputId": "f1fe5137-bc2f-4f4c-817c-700c275a66c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.16)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.32 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.32)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.66.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.32->langchain) (24.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.32->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.4)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.19.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.155.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.25.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.10.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.12.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.66.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.27.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.62.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.12.14)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n",
            "Response: Error: module 'google.generativeai' has no attribute 'chat'\n",
            "Query: What is 25 multiplied by 4?\n",
            "Response: Error: module 'google.generativeai' has no attribute 'chat'\n",
            "----------------------------------------\n",
            "Query: Now divide the result by 5.\n",
            "Response: Error: module 'google.generativeai' has no attribute 'chat'\n",
            "----------------------------------------\n",
            "Query: Add 10 to that.\n",
            "Response: Error: module 'google.generativeai' has no attribute 'chat'\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is 15 divided by 3?\"\n",
        "response = handle_query(query)\n",
        "print(f\"Response: {response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQeYoM2x5l9Y",
        "outputId": "ef3c4bd1-7036-4327-fc19-62197dc90c95"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Error: module 'google.generativeai' has no attribute 'chat'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example with multiple queries\n",
        "queries = [\n",
        "    \"What is 25 multiplied by 4?\",\n",
        "    \"Now divide the result by 5.\",\n",
        "    \"Add 10 to that.\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    print(\"Query:\", q)\n",
        "    print(\"Response:\", handle_query(q))\n",
        "    print(\"-\" * 40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktLvQFNU5oC5",
        "outputId": "741e2bcc-c783-4fec-c90a-7742a0b66a9f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: What is 25 multiplied by 4?\n",
            "Response: Error: module 'google.generativeai' has no attribute 'chat'\n",
            "----------------------------------------\n",
            "Query: Now divide the result by 5.\n",
            "Response: Error: module 'google.generativeai' has no attribute 'chat'\n",
            "----------------------------------------\n",
            "Query: Add 10 to that.\n",
            "Response: Error: module 'google.generativeai' has no attribute 'chat'\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function /tool Calling"
      ],
      "metadata": {
        "id": "E4CnaHBc5ydC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q \"google-generativeai>=0.7.2\""
      ],
      "metadata": {
        "id": "5JlgOie95zrn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=userdata.get(\"GOOGLE_API_KEY\"))"
      ],
      "metadata": {
        "id": "NkPERynq53kI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Music Setup"
      ],
      "metadata": {
        "id": "03PRySGa5_BR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def start_music():\n",
        "    \"\"\"Turn on the music system.\"\"\"\n",
        "    print(\"MUSICBOT: Music started.\")\n",
        "\n",
        "def set_music_volume(level: int):\n",
        "    \"\"\"Set the music volume. Music must be started for this to work.\"\"\"\n",
        "    print(f\"MUSICBOT: Music volume set to {level}.\")\n",
        "\n",
        "def stop_music():\n",
        "    \"\"\"Stop the music.\"\"\"\n",
        "    print(\"MUSICBOT: Music stopped.\")\n",
        "\n",
        "music_controls = [start_music, set_music_volume, stop_music]\n",
        "instruction = \"You are a helpful music system bot. You can start music, adjust the volume, and stop music. Do not perform any other tasks.\"\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    \"models/gemini-1.5-flash\", tools=music_controls, system_instruction=instruction\n",
        ")\n",
        "\n",
        "chat = model.start_chat()\n",
        "\n",
        "from google.generativeai.types import content_types\n",
        "from collections.abc import Iterable\n",
        "\n",
        "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
        "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
        "    return content_types.to_tool_config(\n",
        "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
        "    )\n",
        "\n",
        "# Mode set to \"none\"\n",
        "tool_config = tool_config_from_mode(\"none\")\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Hi, I am John. Tell me about your work?\", tool_config=tool_config\n",
        ")\n",
        "print(response.text)\n",
        "\n",
        "# Mode set to \"auto\"\n",
        "tool_config = tool_config_from_mode(\"auto\")\n",
        "\n",
        "response = chat.send_message(\"Start the music!\", tool_config=tool_config)\n",
        "print(response.parts[0])\n",
        "\n",
        "chat.rewind()  # You are not actually calling the function, so remove this from the history.\n",
        "\n",
        "# Available functions\n",
        "available_fns = [\"set_music_volume\", \"stop_music\"]\n",
        "\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "response = chat.send_message(\"Set the volume to 7!\", tool_config=tool_config)\n",
        "print(response.parts[0])\n",
        "\n",
        "# Available functions with start_music\n",
        "available_fns = [\"start_music\", \"set_music_volume\", \"stop_music\"]\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "response = auto_chat.send_message(\"It's too quiet in here, start the music and set volume to 5, then stop it\", tool_config=tool_config)\n",
        "print(response.parts[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "VMHM7D5H57YI",
        "outputId": "cb8ad041-8707-410a-9cfe-3db97c60cf72"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm a music system bot.  I can start playing music, adjust the volume higher or lower, and stop the music.\n",
            "\n",
            "function_call {\n",
            "  name: \"start_music\"\n",
            "  args {\n",
            "  }\n",
            "}\n",
            "\n",
            "function_call {\n",
            "  name: \"set_music_volume\"\n",
            "  args {\n",
            "    fields {\n",
            "      key: \"level\"\n",
            "      value {\n",
            "        number_value: 7\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "MUSICBOT: Music started.\n",
            "MUSICBOT: Music volume set to 5.0.\n",
            "MUSICBOT: Music stopped.\n",
            "text: \"Done.\\n\"\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tool_config = tool_config_from_mode(\"none\")\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Hi I am Danish,Tell me about your work?\", tool_config=tool_config\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "aaWMjtBg8kZ8",
        "outputId": "fd77a393-4db3-4281-d52b-cbbcfb9c9332"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'm a music system bot. I can start music playback, adjust the volume (louder or softer), and stop the music.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "available_fns = [\"start_music\",\"set_music_volume\", \"stop_music\"]\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "respones = auto_chat.send_message(\"Start Music for Alif Aslam, set up music maximum and then stop\", tool_config=tool_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "yPuWnpdd6X06",
        "outputId": "b694e799-ff32-4be0-e586-cc930a3fd8a1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MUSICBOT: Music started.\n",
            "MUSICBOT: Music volume set to 10.0.\n",
            "MUSICBOT: Music stopped.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lighting"
      ],
      "metadata": {
        "id": "MNjI58hL8yss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def enable_lights():\n",
        "    \"\"\"Turn on the lighting system.\"\"\"\n",
        "    print(\"LIGHTBOT: Lights enabled.\")\n",
        "\n",
        "\n",
        "def set_light_color(rgb_hex: str):\n",
        "    \"\"\"Set the light color. Lights must be enabled for this to work.\"\"\"\n",
        "    print(f\"LIGHTBOT: Lights set to {rgb_hex}.\")\n",
        "\n",
        "\n",
        "def stop_lights():\n",
        "    \"\"\"Stop flashing lights.\"\"\"\n",
        "    print(\"LIGHTBOT: Lights turned off.\")\n",
        "\n",
        "\n",
        "light_controls = [enable_lights, set_light_color, stop_lights]\n",
        "instruction = \"You are a helpful lighting system bot. You can turn lights on and off, and you can set the color. Do not perform any other tasks.\"\n",
        "\n",
        "model = genai.GenerativeModel(\n",
        "    \"models/gemini-1.5-pro\", tools=light_controls, system_instruction=instruction\n",
        ")\n",
        "\n",
        "chat = model.start_chat()"
      ],
      "metadata": {
        "id": "fi8Z-fQ-80Ev"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Helper function for setting function_calling_config on tool_config"
      ],
      "metadata": {
        "id": "58zEx6Qo87LL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.generativeai.types import content_types\n",
        "from collections.abc import Iterable\n",
        "\n",
        "\n",
        "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
        "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
        "    return content_types.to_tool_config(\n",
        "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
        "    )"
      ],
      "metadata": {
        "id": "MTwhEcWH82-x"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Text-only mode: NONE\"\n",
        "means that I should not use any tools and should reply only with text, just like a normal chat."
      ],
      "metadata": {
        "id": "eBAqBX8Q9AR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_config = tool_config_from_mode(\"none\")\n",
        "\n",
        "response = chat.send_message(\n",
        "    \"Hi I am Danish,Tell me about your work?\", tool_config=tool_config\n",
        ")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "FdoeOjsI9Dy0",
        "outputId": "43cd107c-c69e-40e2-c11f-3252bea22944"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I can turn lights on and off, and I can set the color.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#AUTO mode:\n",
        "I can decide whether to respond in text or use tools to give you the best answer."
      ],
      "metadata": {
        "id": "J47uj03d-RW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tool_config = tool_config_from_mode(\"auto\")\n",
        "\n",
        "response = chat.send_message(\"Light this place up!\", tool_config=tool_config)\n",
        "print(response.parts[0])\n",
        "chat.rewind();  # You are not actually calling the function, so remove this from the history."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "9vMd6cdQ-Ujl",
        "outputId": "b3b4f091-6e42-4bbf-ed84-89352c3c8d78"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "function_call {\n",
            "  name: \"enable_lights\"\n",
            "  args {\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Function-calling mode: ANY means the model must use a tool whenever it answers.\n",
        "\n",
        "\n",
        "*  If allowed_function_names is given, the model can only use those tools\n",
        "* If allowed_function_names is not given, the model can use any tool.\n"
      ],
      "metadata": {
        "id": "xlUZ80M_-apQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "available_fns = [\"set_light_color\", \"stop_lights\"]\n",
        "\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "response = chat.send_message(\"Make this place Skyblue!\", tool_config=tool_config)\n",
        "print(response.parts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "XDHn7iNE-oAf",
        "outputId": "0340c34d-c8ec-4c06-fbc4-371dbb7e3775"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "function_call {\n",
            "  name: \"set_light_color\"\n",
            "  args {\n",
            "    fields {\n",
            "      key: \"rgb_hex\"\n",
            "      value {\n",
            "        string_value: \"87CEEB\"\n",
            "      }\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Automatic function calling"
      ],
      "metadata": {
        "id": "D_3XtCur-tPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "available_fns = [\"enable_lights\",\"set_light_color\", \"stop_lights\"]\n",
        "tool_config = tool_config_from_mode(\"any\", available_fns)\n",
        "\n",
        "auto_chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "respones = auto_chat.send_message(\"It's awful dark in here and Make color blue and than switch off the light\", tool_config=tool_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Vtr6t3-U-ur5",
        "outputId": "6dcea4ce-2b88-4b0f-ecb9-d8bc04950fb5"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIGHTBOT: Lights enabled.\n",
            "LIGHTBOT: Lights set to 0000FF.\n",
            "LIGHTBOT: Lights turned off.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#brightness Lighting"
      ],
      "metadata": {
        "id": "X7wtpKXq-4SS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Literal\n",
        "\n",
        "def set_light_values(brightness: int, color_temp: Literal[\"daylight\", \"cool\", \"warm\"]):\n",
        "    \"\"\"Set the brightness and color temperature of a room light. (mock API).\n",
        "\n",
        "    Args:\n",
        "        brightness: Light level from 0 to 100. Zero is off and 100 is full brightness\n",
        "        color_temp: Color temperature of the light fixture, which can be `daylight`, `cool` or `warm`.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the set brightness and color temperature.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        \"brightness\": brightness,\n",
        "        \"colorTemperature\": color_temp\n",
        "    }\n",
        "\n",
        "model = genai.GenerativeModel(model_name='gemini-1.5-flash',\n",
        "                              tools=[set_light_values])\n",
        "\n",
        "chat = model.start_chat(enable_automatic_function_calling=True)\n",
        "response = chat.send_message('Dim the lights so the room feels cozy and warm.')\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "tJNbCCf3_BQR",
        "outputId": "0d8c79e4-44b7-4616-994c-e95b014fdaf1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OK. I've dimmed the lights to 30% brightness and set the color temperature to warm.  Is there anything else?\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Parallel function calling"
      ],
      "metadata": {
        "id": "z0cfUQqB_Igk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def power_disco_ball(power: bool) -> bool:\n",
        "    \"\"\"Powers the spinning disco ball.\"\"\"\n",
        "    print(f\"Disco ball is {'spinning!' if power else 'stopped.'}\")\n",
        "    return True\n",
        "\n",
        "\n",
        "def start_music(energetic: bool, loud: bool, bpm: int) -> str:\n",
        "    \"\"\"Play some music matching the specified parameters.\n",
        "\n",
        "    Args:\n",
        "      energetic: Whether the music is energetic or not.\n",
        "      loud: Whether the music is loud or not.\n",
        "      bpm: The beats per minute of the music.\n",
        "\n",
        "    Returns: The name of the song being played.\n",
        "    \"\"\"\n",
        "    print(f\"Starting music! {energetic=} {loud=}, {bpm=}\")\n",
        "    return \"Never gonna give you up.\"\n",
        "\n",
        "\n",
        "def dim_lights(brightness: float) -> bool:\n",
        "    \"\"\"Dim the lights.\n",
        "\n",
        "    Args:\n",
        "      brightness: The brightness of the lights, 0.0 is off, 1.0 is full.\n",
        "    \"\"\"\n",
        "    print(f\"Lights are now set to {brightness:.0%}\")\n",
        "    return True"
      ],
      "metadata": {
        "id": "y6Hw_MI7_KDH"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the model up with tools.\n",
        "house_fns = [power_disco_ball, start_music, dim_lights]\n",
        "\n",
        "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\", tools=house_fns)\n",
        "\n",
        "# Call the API.\n",
        "chat = model.start_chat()\n",
        "response = chat.send_message(\"Turn this place into a party!\")\n",
        "\n",
        "# Print out each of the function calls requested from this single call.\n",
        "for part in response.parts:\n",
        "    if fn := part.function_call:\n",
        "        args = \", \".join(f\"{key}={val}\" for key, val in fn.args.items())\n",
        "        print(f\"{fn.name}({args})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "_-tHtYT9_Oeo",
        "outputId": "88eb4116-4256-4699-aa8d-653989d55c0f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "power_disco_ball(power=True)\n",
            "start_music(loud=True, energetic=True, bpm=120.0)\n",
            "dim_lights(brightness=0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulate the responses from the specified tools.\n",
        "responses = {\n",
        "    \"power_disco_ball\": True,\n",
        "    \"start_music\": \"Never gonna give you up.\",\n",
        "    \"dim_lights\": True,\n",
        "}\n",
        "\n",
        "# Build the response parts.\n",
        "response_parts = [\n",
        "    genai.protos.Part(function_response=genai.protos.FunctionResponse(name=fn, response={\"result\": val}))\n",
        "    for fn, val in responses.items()\n",
        "]\n",
        "\n",
        "response = chat.send_message(response_parts)\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "T9ym4pXI_V02",
        "outputId": "d68b4724-d926-4080-e2f3-727a74ea24b2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Party started!  Never Gonna Give You Up is playing, the disco ball is spinning, and the lights are dimmed to 50% brightness.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}